{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics-Based Impact Approximation\n",
    "\n",
    "This notebook demonstrates **metrics-based impact approximation** using `evaluate_impact()`.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. User provides `products.csv`\n",
    "2. User configures `DATA.ENRICHMENT` section\n",
    "3. User calls `evaluate_impact(config.yaml)`\n",
    "4. Engine handles everything internally (adapter, enrichment, transform, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:49:59.585332Z",
     "iopub.status.busy": "2026-01-24T14:49:59.585072Z",
     "iopub.status.idle": "2026-01-24T14:50:00.189184Z",
     "shell.execute_reply": "2026-01-24T14:50:00.188601Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from impact_engine import evaluate_impact\n",
    "from online_retail_simulator import simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Products Catalog\n",
    "\n",
    "In production, this would be your actual product catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:50:00.190504Z",
     "iopub.status.busy": "2026-01-24T14:50:00.190368Z",
     "iopub.status.idle": "2026-01-24T14:50:00.202838Z",
     "shell.execute_reply": "2026-01-24T14:50:00.202342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_path = Path(\"output/demo_metrics_approximation\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run simulation using config file\n",
    "job_info = simulate(\"configs/demo_metrics_approximation_catalog.yaml\")\n",
    "products = job_info.load_df(\"products\")\n",
    "\n",
    "products_path = output_path / \"products.csv\"\n",
    "products.to_csv(products_path, index=False)\n",
    "\n",
    "print(f\"Created: {products_path}\")\n",
    "print(f\"Products: {len(products)}\")\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Metrics Approximation\n",
    "\n",
    "Configure the impact engine with:\n",
    "- **ENRICHMENT**: Quality boost parameters\n",
    "- **TRANSFORM**: Prepare data for approximation\n",
    "- **MODEL**: `metrics_approximation` with response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:50:00.203895Z",
     "iopub.status.busy": "2026-01-24T14:50:00.203796Z",
     "iopub.status.idle": "2026-01-24T14:50:00.207243Z",
     "shell.execute_reply": "2026-01-24T14:50:00.206862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to: output/demo_metrics_approximation/config.yaml\n",
      "\n",
      "ENRICHMENT: product_detail_boost\n",
      "TRANSFORM: prepare_simulator_for_approximation\n",
      "MODEL: metrics_approximation\n"
     ]
    }
   ],
   "source": [
    "# Metrics approximation configuration\n",
    "config = {\n",
    "    \"DATA\": {\n",
    "        \"SOURCE\": {\n",
    "            \"type\": \"simulator\",\n",
    "            \"CONFIG\": {\n",
    "                \"mode\": \"rule\",\n",
    "                \"seed\": 42,\n",
    "                \"start_date\": \"2024-01-01\",\n",
    "                \"end_date\": \"2024-01-14\",\n",
    "                \"path\": str(products_path),\n",
    "            },\n",
    "        },\n",
    "        \"ENRICHMENT\": {\n",
    "            \"FUNCTION\": \"product_detail_boost\",\n",
    "            \"PARAMS\": {\n",
    "                \"enrichment_fraction\": 1.0,\n",
    "                \"enrichment_start\": \"2024-01-08\",\n",
    "                \"quality_boost\": 0.15,\n",
    "                \"seed\": 42,\n",
    "            },\n",
    "        },\n",
    "        \"TRANSFORM\": {\"FUNCTION\": \"prepare_simulator_for_approximation\", \"PARAMS\": {}},\n",
    "    },\n",
    "    \"MEASUREMENT\": {\n",
    "        \"MODEL\": \"metrics_approximation\",\n",
    "        \"PARAMS\": {\"RESPONSE\": {\"FUNCTION\": \"linear\", \"PARAMS\": {\"coefficient\": 0.5}}},\n",
    "    },\n",
    "}\n",
    "\n",
    "config_path = output_path / \"config.yaml\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "print(f\"\\nENRICHMENT: {config['DATA']['ENRICHMENT']['FUNCTION']}\")\n",
    "print(f\"TRANSFORM: {config['DATA']['TRANSFORM']['FUNCTION']}\")\n",
    "print(f\"MODEL: {config['MEASUREMENT']['MODEL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Impact Evaluation\n",
    "\n",
    "A single call to `evaluate_impact()` handles everything:\n",
    "- Engine creates CatalogSimulatorAdapter\n",
    "- Adapter simulates metrics\n",
    "- Adapter generates product_details\n",
    "- Adapter applies enrichment (quality boost)\n",
    "- Transform extracts quality_before/quality_after\n",
    "- MetricsApproximationAdapter computes impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:50:00.208046Z",
     "iopub.status.busy": "2026-01-24T14:50:00.207964Z",
     "iopub.status.idle": "2026-01-24T14:50:00.247395Z",
     "shell.execute_reply": "2026-01-24T14:50:00.246755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: /home/peisenha/office/business/eisenhauer-io/tools/impact-engine/documentation/notebooks/output/demo_metrics_approximation/results/job-impact-engine-20260124-065000-a59bdc83/results/impact_results.json\n"
     ]
    }
   ],
   "source": [
    "results_path = evaluate_impact(str(config_path), str(output_path / \"results\"))\n",
    "print(f\"Results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:50:00.248481Z",
     "iopub.status.busy": "2026-01-24T14:50:00.248390Z",
     "iopub.status.idle": "2026-01-24T14:50:00.250985Z",
     "shell.execute_reply": "2026-01-24T14:50:00.250609Z"
    }
   },
   "outputs": [],
   "source": "with open(results_path) as f:\n    results = json.load(f)\n\ndata = results[\"data\"]\nmodel_params = data[\"model_params\"]\nestimates = data[\"impact_estimates\"]\nsummary = data[\"model_summary\"]\n\nprint(\"=\" * 60)\nprint(\"METRICS-BASED IMPACT APPROXIMATION RESULTS\")\nprint(\"=\" * 60)\n\nprint(f\"\\nModel Type: {results['model_type']}\")\nprint(f\"Response Function: {model_params['response_function']}\")\n\nprint(\"\\n--- Aggregate Impact Estimates ---\")\nprint(f\"Total Impact:        ${estimates['impact']:.2f}\")\nprint(f\"Number of Products:  {summary['n_products']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T14:50:00.252013Z",
     "iopub.status.busy": "2026-01-24T14:50:00.251921Z",
     "iopub.status.idle": "2026-01-24T14:50:00.254254Z",
     "shell.execute_reply": "2026-01-24T14:50:00.253853Z"
    }
   },
   "outputs": [],
   "source": "from pathlib import Path\n\nimport pandas as pd\n\n# Per-product data is now in a separate parquet file (prefixed with model type)\nresults_dir = Path(results_path).parent\nper_product_path = results_dir / \"metrics_approximation__product_level_impacts.parquet\"\nper_product_df = pd.read_parquet(per_product_path)\n\nprint(\"\\n--- Per-Product Breakdown ---\")\nprint(\"-\" * 60)\nprint(f\"{'Product':<20} {'Delta Quality':<15} {'Baseline':<12} {'Impact':<12}\")\nprint(\"-\" * 60)\nfor _, p in per_product_df.iterrows():\n    print(\n        f\"{p['product_id']:<20} {p['delta_metric']:<15.4f} \"\n        f\"${p['baseline_outcome']:<11.2f} ${p['impact']:<11.2f}\"\n    )\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Demo Complete!\")\nprint(\"=\" * 60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}